{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ed923f",
   "metadata": {},
   "source": [
    "## Protein Hunter Boltz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üß© Setup and Core Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import contextlib\n",
    "import io\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "from viewer.view import view\n",
    "from LigandMPNN.wrapper import LigandMPNNWrapper\n",
    "\n",
    "os.chdir(\"./boltz\")\n",
    "print(os.getcwd())\n",
    "\n",
    "from model_utils import (\n",
    "    get_boltz_model,\n",
    "    load_canonicals,\n",
    "    process_msa,\n",
    "    smart_split,\n",
    "    clean_memory,\n",
    "    save_pdb,\n",
    "    chain_to_number,\n",
    "    sample_seq,\n",
    "    shallow_copy_tensor_dict,\n",
    "    binder_binds_contacts,\n",
    "    plot_run_metrics,\n",
    "    get_cif,\n",
    "    run_alphafold_step,\n",
    "    run_rosetta_step,\n",
    "    run_prediction,\n",
    "    design_sequence,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Core functionality imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üß¨ Boltz Configuration Parameters\n",
    "# --- General Setup ---\n",
    "gpu_id = 0  # @param {type:\"integer\"}\n",
    "grad_enabled = False  # @param {type:\"boolean\"}\n",
    "name = \"PDL1_two_binder\"  # @param {type:\"string\"}\n",
    "mode = \"binder\"  # @param [\"unconditional\", \"binder\"]\n",
    "num_designs = 3  # @param {type:\"integer\"}\n",
    "num_cycles = 5  # @param {type:\"integer\"}\n",
    "binder_chain = \"A\"  # @param {type:\"string\"}\n",
    "save_dir = f\"../results_boltz/{name}\"\n",
    "work_dir = os.getcwd()\n",
    "\n",
    "# --- Sequence Length ---\n",
    "min_design_protein_length = 100  # @param {type:\"integer\"}\n",
    "max_design_protein_length = 150  # @param {type:\"integer\"}\n",
    "\n",
    "# --- Target Protein(s) ---\n",
    "protein_ids = \"B\"  # @param {type:\"string\"}\n",
    "protein_seqs = \"MAQVQLVETGGGLVQPGGSLRLSCTASGFTFSMHAMTWYRQAPGKQRELVAVITSHGDRANYTDSVRGRFTISRDNTKNMVYLQMNSLKPEDTAVYYCNVPRYDSWGQGTQVTVSSGGLPET\"  # @param {type:\"string\"}\n",
    "protein_msas = (\n",
    "    \"\"  # \"\" means generate, \"empty\" is single sequence # @param {type:\"string\"}\n",
    ")\n",
    "cyclics = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# --- Non-Protein Components (Ligand/Nucleic Acid) ---\n",
    "ligand_id = \"C\"\n",
    "ligand_smiles = \"\"  # @param {type:\"string\"}\n",
    "ligand_ccd = \"SAM\"  # @param {type:\"string\"}\n",
    "nucleic_type = \"dna\"\n",
    "nucleic_id = \"\"\n",
    "nucleic_seq = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# --- Templates and Constraints ---\n",
    "template_path = \"\"\n",
    "template_chain_id = \"\"\n",
    "add_constraints = False  # @param {type:\"boolean\"}\n",
    "contact_residues = \"\"  # e.g., \"1,2,5,10\" on target chain # @param {type:\"string\"}\n",
    "constraint_target_chain = \"B\"  # Target chain for contacts # @param {type:\"string\"}\n",
    "contact_cutoff = 10.0  # @param {type:\"number\"}\n",
    "max_contact_filter_retries = 6  # @param {type:\"integer\"}\n",
    "no_contact_filter = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# --- Model & Diffusion Parameters ---\n",
    "no_potentials = True  # @param {type:\"boolean\"}\n",
    "diffuse_steps = 200  # @param {type:\"integer\"}\n",
    "recycling_steps = 3  # @param {type:\"integer\"}\n",
    "boltz_model_version = \"boltz2\"  # @param [\"boltz1\", \"boltz2\"]\n",
    "boltz_model_path = os.path.expanduser(\"~/.boltz/boltz2_conf.ckpt\")\n",
    "ccd_path = Path(os.path.expanduser(\"~/.boltz/mols\"))\n",
    "logmd = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# --- Design & Optimization ---\n",
    "randomly_kill_helix_feature = False  # @param {type:\"boolean\"}\n",
    "negative_helix_constant = 0.2  # @param {type:\"number\"}\n",
    "alanine_bias = True  # @param {type:\"boolean\"}\n",
    "temperature_start = 0.05  # @param {type:\"number\"}\n",
    "temperature_end = 0.001  # @param {type:\"number\"}\n",
    "alanine_bias_start = -0.5  # @param {type:\"number\"}\n",
    "alanine_bias_end = -0.2  # @param {type:\"number\"}\n",
    "omit_AA = \"C\"  # @param {type:\"string\"}\n",
    "exclude_P = False  # @param {type:\"boolean\"}\n",
    "frac_X = 0.5  # @param {type:\"number\"}\n",
    "high_iptm_threshold = 0.8  # @param {type:\"number\"}\n",
    "\n",
    "# --- Optional: Validation Parameters (External Dependencies) ---\n",
    "alphafold_dir = os.path.expanduser(\"~/alphafold3\")\n",
    "af3_docker_name = \"alphafold3_yc\"\n",
    "af3_database_settings = os.path.expanduser(\"~/alphafold3/alphafold3_data_save\")\n",
    "hmmer_path = os.path.expanduser(\"~/.conda/envs/alphafold3_venv\")\n",
    "use_msa_for_af3 = False\n",
    "plot = True  # @param {type:\"boolean\"}\n",
    "viewer = True  # @param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "# Re-package parameters into an 'args' object (simple class for dot notation)\n",
    "class Args:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "\n",
    "args = Args(**locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚öôÔ∏è Initialize Models and Prepare Base Data\n",
    "\n",
    "# --- 1. Model Initialization ---\n",
    "device = (\n",
    "    f\"cuda:{args.gpu_id}\" if torch.cuda.is_available() and args.gpu_id >= 0 else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "predict_args = {\n",
    "    \"recycling_steps\": args.recycling_steps,\n",
    "    \"sampling_steps\": args.diffuse_steps,\n",
    "    \"diffusion_samples\": 1,\n",
    "    \"write_confidence_summary\": True,\n",
    "    \"write_full_pae\": False,\n",
    "    \"write_full_pde\": False,\n",
    "    \"max_parallel_samples\": 1,\n",
    "}\n",
    "\n",
    "ccd_lib = load_canonicals(os.path.expanduser(str(args.ccd_path)))\n",
    "boltz_model = get_boltz_model(\n",
    "    checkpoint=args.boltz_model_path,\n",
    "    predict_args=predict_args,\n",
    "    device=device,\n",
    "    model_version=args.boltz_model_version,\n",
    "    no_potentials=args.no_potentials,\n",
    "    grad_enabled=args.grad_enabled,\n",
    ")\n",
    "designer = LigandMPNNWrapper(os.path.join(args.work_dir, \"../LigandMPNN/run.py\"))\n",
    "protein_hunter_save_dir = os.path.join(args.save_dir, \"0_protein_hunter_design\")\n",
    "os.makedirs(protein_hunter_save_dir, exist_ok=True)\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "# --- 2. Data Preparation (Condensed from _build_initial_data_dict) ---\n",
    "sequences = []\n",
    "# Process multi-chain/MSA inputs\n",
    "protein_ids_list = smart_split(args.protein_ids)\n",
    "protein_seqs_list = smart_split(args.protein_seqs)\n",
    "protein_msas_list = (\n",
    "    smart_split(args.protein_msas)\n",
    "    if args.protein_msas\n",
    "    else [\"\"] * len(protein_ids_list)\n",
    ")\n",
    "cyclics_list = (\n",
    "    smart_split(args.cyclics) if args.cyclics else [\"False\"] * len(protein_ids_list)\n",
    ")\n",
    "\n",
    "max_len = max(\n",
    "    len(protein_ids_list),\n",
    "    len(protein_seqs_list),\n",
    "    len(protein_msas_list),\n",
    "    len(cyclics_list),\n",
    ")\n",
    "for l in [protein_ids_list, protein_seqs_list, protein_msas_list, cyclics_list]:\n",
    "    while len(l) < max_len:\n",
    "        l.append(\"\")\n",
    "\n",
    "seq_to_indices = defaultdict(list)\n",
    "for idx, seq in enumerate(protein_seqs_list):\n",
    "    if seq:\n",
    "        seq_to_indices[seq].append(idx)\n",
    "seq_to_final_msa = {}\n",
    "\n",
    "# Suppress MSA generation output during this phase\n",
    "with contextlib.redirect_stdout(io.StringIO()) as f:\n",
    "    for seq, idx_list in seq_to_indices.items():\n",
    "        chosen_msa = next(\n",
    "            (\n",
    "                protein_msas_list[i]\n",
    "                for i in idx_list\n",
    "                if protein_msas_list[i] and protein_msas_list[i] != \"empty\"\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if chosen_msa is None:\n",
    "            chosen_msa = \"\"\n",
    "\n",
    "        if chosen_msa == \"\":\n",
    "            pid = (\n",
    "                protein_ids_list[idx_list[0]]\n",
    "                if protein_ids_list[idx_list[0]]\n",
    "                else f\"CHAIN_{idx_list[0]}\"\n",
    "            )\n",
    "            msa_value = process_msa(pid, seq, Path(protein_hunter_save_dir))\n",
    "            seq_to_final_msa[seq] = str(msa_value)\n",
    "        elif chosen_msa == \"empty\":\n",
    "            seq_to_final_msa[seq] = \"empty\"\n",
    "        else:\n",
    "            seq_to_final_msa[seq] = chosen_msa\n",
    "\n",
    "# Build sequences list and add X-binder\n",
    "for pid, seq, cyc in zip(protein_ids_list, protein_seqs_list, cyclics_list):\n",
    "    if not pid or not seq:\n",
    "        continue\n",
    "    final_msa = seq_to_final_msa.get(seq, \"empty\")\n",
    "    cyc_val = cyc.lower() in [\"true\", \"1\", \"yes\"]\n",
    "    sequences.append(\n",
    "        {\"protein\": {\"id\": [pid], \"sequence\": seq, \"msa\": final_msa, \"cyclic\": cyc_val}}\n",
    "    )\n",
    "sequences.append(\n",
    "    {\n",
    "        \"protein\": {\n",
    "            \"id\": [args.binder_chain],\n",
    "            \"sequence\": \"X\",\n",
    "            \"msa\": \"empty\",\n",
    "            \"cyclic\": False,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "if args.ligand_smiles:\n",
    "    sequences.append({\"ligand\": {\"id\": [args.ligand_id], \"smiles\": args.ligand_smiles}})\n",
    "elif args.ligand_ccd:\n",
    "    sequences.append({\"ligand\": {\"id\": [args.ligand_id], \"ccd\": args.ligand_ccd}})\n",
    "if args.nucleic_seq:\n",
    "    sequences.append(\n",
    "        {args.nucleic_type: {\"id\": [args.nucleic_id], \"sequence\": args.nucleic_seq}}\n",
    "    )\n",
    "\n",
    "# Handle templates and constraints\n",
    "templates = []\n",
    "if args.template_path:\n",
    "    template_path_list = smart_split(args.template_path)\n",
    "    template_chain_id_list = (\n",
    "        smart_split(args.template_chain_id) if args.template_chain_id else []\n",
    "    )\n",
    "    template_files = [get_cif(tp) for tp in template_path_list]\n",
    "    for i, template_file in enumerate(template_files):\n",
    "        t_block = (\n",
    "            {\"cif\": template_file}\n",
    "            if template_file.endswith(\".cif\")\n",
    "            else {\"pdb\": template_file}\n",
    "        )\n",
    "        if template_chain_id_list and i < len(template_chain_id_list):\n",
    "            t_block[\"chain_id\"] = template_chain_id_list[i]\n",
    "        templates.append(t_block)\n",
    "\n",
    "data = {\"sequences\": sequences}\n",
    "if templates:\n",
    "    data[\"templates\"] = templates\n",
    "pocket_conditioning = args.add_constraints\n",
    "\n",
    "if args.add_constraints:\n",
    "    residues = args.contact_residues.split(\",\")\n",
    "    contacts = [\n",
    "        [args.constraint_target_chain, int(res)]\n",
    "        for res in residues\n",
    "        if res.strip() != \"\"\n",
    "    ]\n",
    "    constraints = [{\"pocket\": {\"binder\": args.binder_chain, \"contacts\": contacts}}]\n",
    "    data[\"constraints\"] = constraints\n",
    "\n",
    "data[\"sequences\"] = sorted(\n",
    "    data[\"sequences\"], key=lambda entry: list(entry.values())[0][\"id\"][0]\n",
    ")\n",
    "\n",
    "any_ligand_or_nucleic = args.ligand_smiles or args.ligand_ccd or args.nucleic_seq\n",
    "model_type = \"ligand_mpnn\" if any_ligand_or_nucleic else \"soluble_mpnn\"\n",
    "\n",
    "print(\"‚úÖ Models ready and base data configured.\")\n",
    "print(\"Mode:\", args.mode)\n",
    "print(\"Data dictionary (base):\\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üöÄ Execute Design and Optimization Loop\n",
    "# Replicate the core logic from _run_design_cycle and run_pipeline's execution part\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "# NOTE: Using viewer object from global scope for incremental updates\n",
    "all_run_metrics = []\n",
    "\n",
    "for design_id in range(args.num_designs):\n",
    "    if viewer:\n",
    "        viewer = view()\n",
    "        viewer.clear()\n",
    "\n",
    "    run_id = str(design_id)\n",
    "    run_save_dir = os.path.join(args.save_dir, f\"run_{run_id}\")\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "\n",
    "    data_cp = copy.deepcopy(data)\n",
    "\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(f\"=== Starting Design Run {run_id}/{args.num_designs - 1} ===\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "    best_iptm = float(\"-inf\")\n",
    "    best_seq = None\n",
    "    best_structure = None\n",
    "    best_output = None\n",
    "    best_pdb_filename = None\n",
    "    best_cycle_idx = -1\n",
    "    best_alanine_percentage = None\n",
    "    run_metrics = {\"run_id\": run_id}\n",
    "\n",
    "    # --- Initial Sequence Assignment ---\n",
    "    binder_length = random.randint(\n",
    "        args.min_design_protein_length, args.max_design_protein_length\n",
    "    )\n",
    "    new_seq = sample_seq(binder_length, exclude_P=args.exclude_P, frac_X=args.frac_X)\n",
    "\n",
    "    # Update binder sequence in the data dictionary copy\n",
    "    for seq_entry in data_cp[\"sequences\"]:\n",
    "        if \"protein\" in seq_entry and args.binder_chain in seq_entry[\"protein\"][\"id\"]:\n",
    "            seq_entry[\"protein\"][\"sequence\"] = new_seq\n",
    "            break\n",
    "    print(f\"Binder initial sequence length: {binder_length}\")\n",
    "\n",
    "    # ========== Cycle 0 structure prediction (with contact filtering) ==========\n",
    "    contact_filter_attempt = 0\n",
    "    pdb_filename = \"\"\n",
    "    structure = None\n",
    "    output = None\n",
    "\n",
    "    while True:\n",
    "        # SUPPRESS UNWANTED MSA MESSAGES during prediction\n",
    "        with contextlib.redirect_stdout(io.StringIO()) as f:\n",
    "            output, structure = run_prediction(\n",
    "                data_cp,\n",
    "                args.binder_chain,\n",
    "                randomly_kill_helix_feature=args.randomly_kill_helix_feature,\n",
    "                negative_helix_constant=args.negative_helix_constant,\n",
    "                boltz_model=boltz_model,\n",
    "                ccd_lib=ccd_lib,\n",
    "                ccd_path=args.ccd_path,\n",
    "                logmd=args.logmd,\n",
    "                device=device,\n",
    "                boltz_model_version=args.boltz_model_version,\n",
    "                pocket_conditioning=pocket_conditioning,\n",
    "            )\n",
    "\n",
    "        # Save Cycle 0 PDB\n",
    "        pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_0.pdb\"\n",
    "        plddts = output[\"plddt\"].detach().cpu().numpy()[0]\n",
    "        save_pdb(structure, output[\"coords\"], plddts, pdb_filename)\n",
    "\n",
    "        # Contact filtering (only if configured)\n",
    "        contact_check_okay = True\n",
    "        if args.contact_residues.strip() and not args.no_contact_filter:\n",
    "            try:\n",
    "                binds = binder_binds_contacts(\n",
    "                    pdb_filename,\n",
    "                    args.binder_chain,\n",
    "                    args.constraint_target_chain,\n",
    "                    args.contact_residues,\n",
    "                    cutoff=args.contact_cutoff,\n",
    "                )\n",
    "                if not binds:\n",
    "                    print(\n",
    "                        \"‚ùå Binder does NOT contact required residues after cycle 0. Retrying...\"\n",
    "                    )\n",
    "                    contact_check_okay = False\n",
    "            except Exception as e:\n",
    "                print(f\"WARNING: Could not perform binder-contact check: {e}\")\n",
    "                contact_check_okay = True\n",
    "\n",
    "        if contact_check_okay:\n",
    "            break\n",
    "        else:\n",
    "            contact_filter_attempt += 1\n",
    "            if contact_filter_attempt >= args.max_contact_filter_retries:\n",
    "                print(\"‚ö†Ô∏è Maximum contact filter retries reached. Proceeding anyway.\")\n",
    "                break\n",
    "\n",
    "            # Resample initial sequence\n",
    "            new_seq = sample_seq(\n",
    "                binder_length, exclude_P=args.exclude_P, frac_X=args.frac_X\n",
    "            )\n",
    "            for seq_entry in data_cp[\"sequences\"]:\n",
    "                if (\n",
    "                    \"protein\" in seq_entry\n",
    "                    and args.binder_chain in seq_entry[\"protein\"][\"id\"]\n",
    "                ):\n",
    "                    seq_entry[\"protein\"][\"sequence\"] = new_seq\n",
    "                    break\n",
    "            clean_memory()\n",
    "\n",
    "    # --- Capture Cycle 0 metrics (same logic as before) ---\n",
    "    binder_chain_idx = chain_to_number[args.binder_chain]\n",
    "    pair_chains = output[\"pair_chains_iptm\"]\n",
    "    if len(pair_chains) > 1:\n",
    "        values = [\n",
    "            (\n",
    "                pair_chains[binder_chain_idx][i].detach().cpu().numpy()\n",
    "                + pair_chains[i][binder_chain_idx].detach().cpu().numpy()\n",
    "            )\n",
    "            / 2.0\n",
    "            for i in range(len(pair_chains))\n",
    "            if i != binder_chain_idx\n",
    "        ]\n",
    "        cycle_0_iptm = float(np.mean(values) if values else 0.0)\n",
    "    else:\n",
    "        cycle_0_iptm = 0.0\n",
    "    run_metrics[\"cycle_0_iptm\"] = cycle_0_iptm\n",
    "    run_metrics[\"cycle_0_plddt\"] = float(\n",
    "        output.get(\"complex_plddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
    "    )\n",
    "    run_metrics[\"cycle_0_iplddt\"] = float(\n",
    "        output.get(\"complex_iplddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
    "    )\n",
    "    run_metrics[\"cycle_0_alanine\"] = 0\n",
    "    run_metrics[\"cycle_0_seq\"] = new_seq\n",
    "\n",
    "    # ===== Optimization Cycles (Cycle 1 to num_cycles) =====\n",
    "    for cycle in range(args.num_cycles):\n",
    "        print(f\"\\n--- Run {run_id}, Cycle {cycle + 1} ---\")\n",
    "\n",
    "        # Calculate temperature and bias\n",
    "        cycle_norm = (cycle / (args.num_cycles - 1)) if args.num_cycles > 1 else 0.0\n",
    "        alpha = args.alanine_bias_start - cycle_norm * (\n",
    "            args.alanine_bias_start - args.alanine_bias_end\n",
    "        )\n",
    "        temperature = args.temperature_start - cycle_norm * (\n",
    "            args.temperature_start - args.temperature_end\n",
    "        )\n",
    "\n",
    "        design_kwargs = {\n",
    "            \"pdb_file\": pdb_filename,\n",
    "            \"temperature\": temperature,\n",
    "            \"chains_to_design\": args.binder_chain,\n",
    "            \"omit_AA\": f\"{args.omit_AA},P\" if cycle == 0 else args.omit_AA,\n",
    "        }\n",
    "        if args.alanine_bias:\n",
    "            design_kwargs[\"bias_AA\"] = f\"A:{alpha}\"\n",
    "\n",
    "        seq_str, logits = design_sequence(designer, model_type, **design_kwargs)\n",
    "        seq = seq_str.split(\":\")[chain_to_number[args.binder_chain]]\n",
    "\n",
    "        alanine_count = seq.count(\"A\")\n",
    "        alanine_percentage = alanine_count / binder_length if binder_length else 0.0\n",
    "        for seq_entry in data_cp[\"sequences\"]:\n",
    "            if (\n",
    "                \"protein\" in seq_entry\n",
    "                and args.binder_chain in seq_entry[\"protein\"][\"id\"]\n",
    "            ):\n",
    "                seq_entry[\"protein\"][\"sequence\"] = seq\n",
    "                break\n",
    "\n",
    "        # SUPPRESS UNWANTED MSA MESSAGES during prediction\n",
    "        with contextlib.redirect_stdout(io.StringIO()) as f:\n",
    "            output, structure = run_prediction(\n",
    "                data_cp,\n",
    "                args.binder_chain,\n",
    "                seq=seq,\n",
    "                randomly_kill_helix_feature=False,\n",
    "                negative_helix_constant=0.0,\n",
    "                boltz_model=boltz_model,\n",
    "                ccd_lib=ccd_lib,\n",
    "                ccd_path=args.ccd_path,\n",
    "                logmd=False,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "        # Compute ipTM\n",
    "        current_chain_idx = chain_to_number[args.binder_chain]\n",
    "        pair_chains = output[\"pair_chains_iptm\"]\n",
    "        if len(pair_chains) > 1:\n",
    "            values = [\n",
    "                (\n",
    "                    pair_chains[current_chain_idx][i].detach().cpu().numpy()\n",
    "                    + pair_chains[i][current_chain_idx].detach().cpu().numpy()\n",
    "                )\n",
    "                / 2.0\n",
    "                for i in range(len(pair_chains))\n",
    "                if i != current_chain_idx\n",
    "            ]\n",
    "            current_iptm = float(np.mean(values) if values else 0.0)\n",
    "        else:\n",
    "            current_iptm = 0.0\n",
    "\n",
    "        # Update best structure\n",
    "        if alanine_percentage <= 0.20 and current_iptm > best_iptm:\n",
    "            best_iptm = current_iptm\n",
    "            best_structure = copy.deepcopy(structure)\n",
    "            best_output = shallow_copy_tensor_dict(output)\n",
    "            best_pdb_filename = (\n",
    "                f\"{run_save_dir}/{args.name}_run_{run_id}_best_structure.pdb\"\n",
    "            )\n",
    "            best_plddts = best_output[\"plddt\"].detach().cpu().numpy()[0]\n",
    "            save_pdb(\n",
    "                best_structure, best_output[\"coords\"], best_plddts, best_pdb_filename\n",
    "            )\n",
    "            best_cycle_idx = cycle + 1\n",
    "            best_seq = seq\n",
    "            best_alanine_percentage = alanine_percentage\n",
    "\n",
    "        # Record metrics\n",
    "        curr_plddt = float(\n",
    "            output.get(\"complex_plddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
    "        )\n",
    "        curr_iplddt = float(\n",
    "            output.get(\"complex_iplddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
    "        )\n",
    "        run_metrics[f\"cycle_{cycle + 1}_iptm\"] = current_iptm\n",
    "        run_metrics[f\"cycle_{cycle + 1}_plddt\"] = curr_plddt\n",
    "        run_metrics[f\"cycle_{cycle + 1}_iplddt\"] = curr_iplddt\n",
    "        run_metrics[f\"cycle_{cycle + 1}_alanine\"] = alanine_count\n",
    "        run_metrics[f\"cycle_{cycle + 1}_seq\"] = seq\n",
    "\n",
    "        print(\n",
    "            f\"ipTM: {current_iptm:.2f}, pLDDT: {curr_plddt:.2f}, iPLDDT: {curr_iplddt:.2f}, Ala%: {alanine_percentage * 100:.1f}\"\n",
    "        )\n",
    "\n",
    "        pdb_filename = (\n",
    "            f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_{cycle + 1}.pdb\"\n",
    "        )\n",
    "        plddts = output[\"plddt\"].detach().cpu().numpy()[0]\n",
    "        save_pdb(structure, output[\"coords\"], plddts, pdb_filename)\n",
    "\n",
    "        if viewer:\n",
    "            viewer.from_pdb(pdb_filename)\n",
    "\n",
    "        clean_memory()\n",
    "\n",
    "    # --- Finalize and Plot Metrics ---\n",
    "    run_metrics[\"best_iptm\"] = float(\n",
    "        best_iptm if best_iptm != float(\"-inf\") else np.nan\n",
    "    )\n",
    "    run_metrics[\"best_cycle\"] = best_cycle_idx\n",
    "    run_metrics[\"best_seq\"] = best_seq\n",
    "    if best_output:\n",
    "        run_metrics[\"best_plddt\"] = float(\n",
    "            best_output.get(\"complex_plddt\", torch.tensor([np.nan]))\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()[0]\n",
    "        )\n",
    "    else:\n",
    "        run_metrics[\"best_plddt\"] = np.nan\n",
    "    all_run_metrics.append(run_metrics)\n",
    "\n",
    "    if args.plot:\n",
    "        plot_run_metrics(run_save_dir, args.name, run_id, args.num_cycles, run_metrics)\n",
    "\n",
    "\n",
    "# ===== Save All Run Metrics to CSV =====\n",
    "summary_csv = os.path.join(args.save_dir, \"summary_all_runs.csv\")\n",
    "df = pd.DataFrame(all_run_metrics)\n",
    "columns = [\"run_id\"]\n",
    "for i in range(args.num_cycles + 1):\n",
    "    columns.extend(\n",
    "        [\n",
    "            f\"cycle_{i}_iptm\",\n",
    "            f\"cycle_{i}_plddt\",\n",
    "            f\"cycle_{i}_iplddt\",\n",
    "            f\"cycle_{i}_alanine\",\n",
    "            f\"cycle_{i}_seq\",\n",
    "        ]\n",
    "    )\n",
    "columns.extend([\"best_iptm\", \"best_cycle\", \"best_plddt\", \"best_seq\"])\n",
    "\n",
    "for col in columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "df = df[[c for c in columns if c in df.columns]]\n",
    "df.to_csv(summary_csv, index=False)\n",
    "print(f\"\\n‚úÖ All run/cycle metrics saved to {summary_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b19c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚öôÔ∏è Optional: Downstream Validation (Requires External Setup)\n",
    "# Determine target type\n",
    "target_type = \"protein\"\n",
    "if args.nucleic_seq:\n",
    "    target_type = \"nucleic\"\n",
    "elif args.ligand_smiles or args.ligand_ccd:\n",
    "    target_type = \"small_molecule\"\n",
    "\n",
    "success_dir = os.path.join(args.save_dir, \"1_af3_rosetta_validation\")\n",
    "high_iptm_yaml_dir = os.path.join(args.save_dir, \"high_iptm_yaml\")\n",
    "\n",
    "# AlphaFold step\n",
    "af_output_dir, af_output_apo_dir, af_pdb_dir, af_pdb_dir_apo = run_alphafold_step(\n",
    "    high_iptm_yaml_dir,\n",
    "    args.alphafold_dir,\n",
    "    args.af3_docker_name,\n",
    "    args.af3_database_settings,\n",
    "    args.hmmer_path,\n",
    "    success_dir,\n",
    "    args.work_dir,\n",
    "    binder_id=args.binder_chain,\n",
    "    gpu_id=args.gpu_id,\n",
    "    high_iptm=True,\n",
    "    use_msa_for_af3=args.use_msa_for_af3,\n",
    ")\n",
    "\n",
    "# Rosetta step\n",
    "run_rosetta_step(\n",
    "    success_dir,\n",
    "    af_pdb_dir,\n",
    "    af_pdb_dir_apo,\n",
    "    binder_id=args.binder_chain,\n",
    "    target_type=target_type,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Pipeline execution complete. Check results in the output directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boltz_ph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
