{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BejWxwaeKIIP"
      },
      "source": [
        "# Protein Hunter Boltz Edition ‚ö°‚ú®üòà"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n0K7DoLHSPr"
      },
      "source": [
        "For more details, read BoltzDesign1 paper **(https://www.biorxiv.org/content/10.1101/2025.10.10.681530v2.full.pdf)**\n",
        "\n",
        "**‚ùó Display Recommendation:**\n",
        "The viewer and visualization tools are optimized for light mode.\n",
        "\n",
        "**‚ùó WARNING:** the following pipeline is in active development and has NOT been experimentally validated in lab. We are releasing the code to allow the community to contribute and build on.\n",
        "\n",
        "**üìß Contact**\n",
        "For feedback, questions or collaboration opportunities, please email yehlin@mit.edu\n",
        "\n",
        "**‚û°Ô∏è Reference**\n",
        "We implemented the visualization of designing trajectories using logMD and py2Dmol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuYz-SbMHPWF",
        "outputId": "85c2811b-939c-49fa-8e8b-0d092135297f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%%time` not found.\n"
          ]
        }
      ],
      "source": [
        "#@title üõ†Ô∏è Fixed setup (~3 minutes)\n",
        "%%time\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# First, navigate to the correct directory\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# Install ProDy from GitHub\n",
        "os.system(\"pip install -q git+https://github.com/prody/ProDy.git\")\n",
        "\n",
        "if not os.path.isdir(\"Protein-Hunter\"):\n",
        "    print(\"Cloning Protein Hunter repository...\")\n",
        "    os.system(\"git clone https://github.com/yehlincho/Protein-Hunter.git\")\n",
        "    print(\"Installing LigandMPNN...\")\n",
        "    os.chdir(\"/content/Protein-Hunter/LigandMPNN\")\n",
        "    os.system(\"mkdir -p model_params\")\n",
        "    os.system(\"bash get_model_params.sh model_params\")\n",
        "    os.system(\"pip install -q ml_collections\")\n",
        "\n",
        "    print(\"Installing Boltz...\")\n",
        "    os.chdir(\"/content/Protein-Hunter/boltz_ph\")\n",
        "\n",
        "    # Install boltz with dependencies\n",
        "    os.system(\"pip install --no-dependencies .\")\n",
        "    os.system(\"pip install -q pypdb py3Dmol py2Dmol logmd tqdm\")\n",
        "    os.system(\"pip install pytorch_lightning \\\n",
        "    'rdkit~=2024.9.5' mashumaro \\\n",
        "    chembl_structure_pipeline \\\n",
        "    'gemmi~=0.6.5' ihm 'modelcif>=1.0' \\\n",
        "    fairscale einx\")\n",
        "\n",
        "    # Add boltz to Python path\n",
        "    boltz_path = \"/content/Protein-Hunter/boltz_ph\"\n",
        "    if boltz_path not in sys.path:\n",
        "        sys.path.insert(0, boltz_path)\n",
        "\n",
        "    os.chdir(\"/content\")\n",
        "else:\n",
        "    # If already installed, just add to path\n",
        "    boltz_path = \"/content/Protein-Hunter/boltz_ph\"\n",
        "    if boltz_path not in sys.path:\n",
        "        sys.path.insert(0, boltz_path)\n",
        "\n",
        "print(\"Setup complete!\")\n",
        "\n",
        "os.environ[\"TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD\"] = \"1\"\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR0MTxn1wBSA",
        "outputId": "ba8cd16d-2db1-428e-c032-81d4f4e3c0da"
      },
      "outputs": [],
      "source": [
        "#@title üõ†Ô∏è download model weights\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/Protein-Hunter/boltz_ph/src\")\n",
        "from boltz.main import download_boltz2\n",
        "from pathlib import Path\n",
        "download_boltz2(Path(\".\"))\n",
        "print(\"Import successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJGAeh4OOXHz",
        "outputId": "2b459f10-7ff9-4332-f9f4-bac5fe1ae23b"
      },
      "outputs": [],
      "source": [
        "# @title üß© Setup and Core Imports\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "import contextlib\n",
        "import io\n",
        "import copy\n",
        "import yaml\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Suppress warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.*\",\n",
        "    category=UserWarning,\n",
        ")\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/Protein-Hunter\")\n",
        "import py2Dmol\n",
        "from LigandMPNN.wrapper import LigandMPNNWrapper\n",
        "\n",
        "from boltz_ph.constants import CHAIN_TO_NUMBER\n",
        "from utils.metrics import get_CA_and_sequence # Used implicitly in design.py\n",
        "from utils.convert import calculate_holo_apo_rmsd, convert_cif_files_to_pdb\n",
        "# -----------------------------\n",
        "\n",
        "from boltz_ph.model_utils import (\n",
        "    binder_binds_contacts,\n",
        "    extract_sequence_from_structure,\n",
        "    clean_memory,\n",
        "    design_sequence,\n",
        "    get_boltz_model,\n",
        "    get_cif,\n",
        "    load_canonicals,\n",
        "    plot_from_pdb,\n",
        "    plot_run_metrics,\n",
        "    process_msa,\n",
        "    run_prediction,\n",
        "    sample_seq,\n",
        "    save_pdb,\n",
        "    shallow_copy_tensor_dict,\n",
        "    smart_split,\n",
        ")\n",
        "print(\"‚úÖ Core functionality imported.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mXmBIVkVOpYa"
      },
      "outputs": [],
      "source": [
        "# @title üß¨ Boltz Configuration Parameters\n",
        "# --- General Setup ---\n",
        "gpu_id = 0\n",
        "grad_enabled = False\n",
        "\n",
        "#@markdown ### Binder options\n",
        "\n",
        "name = \"PDL1_SAM_binder\"  # @param {type:\"string\"}\n",
        "mode = \"binder\"  # @param [\"unconditional\", \"binder\"]\n",
        "\n",
        "num_designs = 2  # @param {type:\"integer\"}\n",
        "num_cycles = 5  # @param {type:\"integer\"}\n",
        "save_dir = f\"/content/results/{name}\"\n",
        "work_dir = os.getcwd()\n",
        "\n",
        "# --- Sequence Length ---\n",
        "min_protein_length = 100  # @param {type:\"integer\"}\n",
        "max_protein_length = 150  # @param {type:\"integer\"}\n",
        "percent_X = 80 # @param [\"0\",\"10\",\"20\",\"30\",\"40\",\"50\",\"60\",\"70\",\"80\",\"90\",\"100\"] {\"type\":\"raw\"}\n",
        "cyclic = False  # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Target options\n",
        "protein_seqs = \"MAQVQLVETGGGLVQPGGSLRLSCTASGFTFSMHAMTWYRQAPGKQRELVAVITSHGDRANYTDSVRGRFTISRDNTKNMVYLQMNSLKPEDTAVYYCNVPRYDSWGQGTQVTVSSGGLPET\"  # @param {type:\"string\"}\n",
        "\n",
        "# --- Non-Protein Components (Ligand/Nucleic Acid) ---\n",
        "ligand_smiles = \"\"  # @param {type:\"string\"}\n",
        "ligand_ccd = \"SAM\"  # @param {type:\"string\"}\n",
        "nucleic_seq = \"\"  # @param {type:\"string\"}\n",
        "nucleic_type = \"dna\" # @param [\"dna\", \"rna\"]\n",
        "\n",
        "\n",
        "#@markdown ### MSA or template options\n",
        "msa_mode = \"mmseqs\" # @param [\"single\", \"mmseqs\"]\n",
        "template_path = \"\" #@param {type:\"string\"}\n",
        "#@markdown - template PDB/mmCIF code or path to template file\n",
        "template_cif_chain_id = \"\" #@param {type:\"string\"}\n",
        "#@markdown - for template mmCIF files, which chain from mmcif file to use for the template\n",
        "\n",
        "\n",
        "#@markdown ### Contact options\n",
        "contact_residues = \"\" # @param {type:\"string\"}  # e.g., \"1,2,5,10\" on target chain \n",
        "#@markdown - Specify which target chain residues must contact the binder (currently only supports protein contacts). For more than two chains, separate by |, e.g., \"1,2,5,10 | 3,5,10\".\n",
        "\n",
        "contact_cutoff = 10.0\n",
        "max_contact_filter_retries = 6\n",
        "\n",
        "# --- Model & Diffusion Parameters ---\n",
        "no_potentials = False if contact_residues else True\n",
        "diffuse_steps = 200\n",
        "recycling_steps = 3\n",
        "boltz_model_version = \"boltz2\"\n",
        "boltz_model_path = \"/content/boltz2_conf.ckpt\"\n",
        "ccd_path = \"/content/mols\"\n",
        "\n",
        "logmd = False\n",
        "\n",
        "\n",
        "#@markdown ### Design options\n",
        "# --- Design & Optimization ---\n",
        "randomly_kill_helix_feature = False  # @param {type:\"boolean\"}\n",
        "negative_helix_constant = 0.2\n",
        "alanine_bias = True  # @param {type:\"boolean\"}\n",
        "alanine_bias_start = -0.5\n",
        "alanine_bias_end = -0.2\n",
        "temperature = 0.1  # @param {type:\"number\"}\n",
        "\n",
        "omit_AA = \"C\"  # @param {type:\"string\"}\n",
        "exclude_P = False\n",
        "high_iptm_threshold = 0.8  # @param {type:\"number\"}\n",
        "high_plddt_threshold = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "plot = True\n",
        "viewer = True\n",
        "\n",
        "# Re-package parameters into an 'args' object (simple class for dot notation)\n",
        "class Args:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "\n",
        "args = Args(**locals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo1Dix4sPTGG",
        "outputId": "d469c5b4-c484-4b2e-f79f-ab1cc61a772a"
      },
      "outputs": [],
      "source": [
        "# @title ‚öôÔ∏è Initialize Models and Prepare Base Data\n",
        "# --- 1. Model Initialization ---\n",
        "device = (\n",
        "    f\"cuda:{args.gpu_id}\" if torch.cuda.is_available() and args.gpu_id >= 0 else \"cpu\"\n",
        ")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "predict_args = {\n",
        "    \"recycling_steps\": args.recycling_steps,\n",
        "    \"sampling_steps\": args.diffuse_steps,\n",
        "    \"diffusion_samples\": 1,\n",
        "    \"write_confidence_summary\": True,\n",
        "    \"write_full_pae\": False,\n",
        "    \"write_full_pde\": False,\n",
        "    \"max_parallel_samples\": 1,\n",
        "}\n",
        "\n",
        "ccd_lib = load_canonicals(os.path.expanduser(str(args.ccd_path)))\n",
        "boltz_model = get_boltz_model(\n",
        "    checkpoint=args.boltz_model_path,\n",
        "    predict_args=predict_args,\n",
        "    device=device,\n",
        "    model_version=args.boltz_model_version,\n",
        "    no_potentials=args.no_potentials,\n",
        "    grad_enabled=args.grad_enabled,\n",
        ")\n",
        "designer = LigandMPNNWrapper(os.path.join(args.work_dir, \"/content/Protein-Hunter/LigandMPNN/run.py\"))\n",
        "protein_hunter_save_dir = os.path.join(args.save_dir, \"0_protein_hunter_design\")\n",
        "os.makedirs(protein_hunter_save_dir, exist_ok=True)\n",
        "os.makedirs(args.save_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# --- 2. Data Preparation (Condensed from _build_initial_data_dict) ---\n",
        "sequences = []\n",
        "\n",
        "# --- MODIFIED: Process sequences and assign chain IDs ---\n",
        "args.binder_chain = \"A\"\n",
        "protein_seqs_list = smart_split(args.protein_seqs) if args.protein_seqs else []\n",
        "\n",
        "if args.msa_mode == \"single\":\n",
        "    protein_msas_list = [\"empty\"] * len(protein_seqs_list)\n",
        "elif args.msa_mode == \"mmseqs\":    \n",
        "    protein_msas_list = [\"mmseqs\"] * len(protein_seqs_list)\n",
        "else:\n",
        "    raise ValueError(f\"Invalid msa_mode: {args.msa_mode}\")\n",
        "# Assign chain IDs\n",
        "protein_chain_ids = [chr(ord('B') + i) for i in range(len(protein_seqs_list))]\n",
        "next_chain_idx = len(protein_chain_ids)\n",
        "\n",
        "ligand_chain_id = None\n",
        "if args.ligand_smiles or args.ligand_ccd:\n",
        "    ligand_chain_id = chr(ord('B') + next_chain_idx)\n",
        "    next_chain_idx += 1\n",
        "    \n",
        "nucleic_chain_id = None\n",
        "if args.nucleic_seq:\n",
        "    nucleic_chain_id = chr(ord('B') + next_chain_idx)\n",
        "    next_chain_idx += 1\n",
        "# --- END MODIFICATIONS ---\n",
        "\n",
        "seq_to_indices = defaultdict(list)\n",
        "for idx, seq in enumerate(protein_seqs_list):\n",
        "    if seq:\n",
        "        seq_to_indices[seq].append(idx)\n",
        "seq_to_final_msa = {}\n",
        "\n",
        "# Suppress MSA generation output during this phase\n",
        "# Suppress MSA generation output during this phase\n",
        "print(\"Processing MSAs (if any)...\")\n",
        "with contextlib.redirect_stdout(io.StringIO()) as f:\n",
        "    for seq, idx_list in seq_to_indices.items():\n",
        "        chosen_msa = next(\n",
        "            (\n",
        "                protein_msas_list[i]\n",
        "                for i in idx_list\n",
        "            ),\n",
        "            None,\n",
        "        )\n",
        "        if chosen_msa == \"mmseqs\":\n",
        "            pid = protein_chain_ids[idx_list[0]]\n",
        "            msa_value = process_msa(pid, seq, Path(protein_hunter_save_dir))\n",
        "            seq_to_final_msa[seq] = str(msa_value)\n",
        "        elif chosen_msa == \"empty\":\n",
        "            seq_to_final_msa[seq] = \"empty\"\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid msa_mode: {args.msa_mode}\")\n",
        "\n",
        "\n",
        "# Build sequences list\n",
        "for i, (seq, msa) in enumerate(zip(protein_seqs_list, protein_msas_list)):\n",
        "    if not seq:\n",
        "        continue\n",
        "    pid = protein_chain_ids[i]\n",
        "    final_msa = seq_to_final_msa.get(seq, \"empty\")\n",
        "    sequences.append(\n",
        "        {\"protein\": {\"id\": [pid], \"sequence\": seq, \"msa\": final_msa}}\n",
        "    )\n",
        "\n",
        "sequences.append(\n",
        "    {\n",
        "        \"protein\": {\n",
        "            \"id\": [\"A\"], # Binder is always 'A'\n",
        "            \"sequence\": \"X\",\n",
        "            \"msa\": \"empty\",\n",
        "            \"cyclic\": args.cyclic,\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "if args.ligand_smiles:\n",
        "    sequences.append({\"ligand\": {\"id\": [ligand_chain_id], \"smiles\": args.ligand_smiles}})\n",
        "elif args.ligand_ccd:\n",
        "    sequences.append({\"ligand\": {\"id\": [ligand_chain_id], \"ccd\": args.ligand_ccd}})\n",
        "if args.nucleic_seq:\n",
        "    sequences.append(\n",
        "        {args.nucleic_type: {\"id\": [nucleic_chain_id], \"sequence\": args.nucleic_seq}}\n",
        "    )\n",
        "\n",
        "# --- Handle templates with 1-to-1 mapping ---\n",
        "templates = []\n",
        "if args.template_path:\n",
        "    template_path_list = smart_split(args.template_path)\n",
        "    template_cif_chain_id_list = (\n",
        "        smart_split(args.template_cif_chain_id) if args.template_cif_chain_id else []\n",
        "    )\n",
        "    \n",
        "    num_proteins = len(protein_chain_ids)\n",
        "    \n",
        "    while len(template_path_list) < num_proteins:\n",
        "        template_path_list.append(\"\")\n",
        "    while len(template_cif_chain_id_list) < num_proteins:\n",
        "        template_cif_chain_id_list.append(\"\")\n",
        "\n",
        "    for i in range(num_proteins):\n",
        "        template_file_path = template_path_list[i]\n",
        "        if not template_file_path:\n",
        "            continue\n",
        "            \n",
        "        template_file = get_cif(template_file_path)\n",
        "        \n",
        "        t_block = (\n",
        "            {\"cif\": template_file}\n",
        "            if template_file.endswith(\".cif\")\n",
        "            else {\"pdb\": template_file}\n",
        "        )\n",
        "        \n",
        "        t_block[\"chain_id\"] = protein_chain_ids[i]\n",
        "        cif_chain = template_cif_chain_id_list[i]\n",
        "        if cif_chain:\n",
        "            t_block[\"cif_chain_id\"] = cif_chain\n",
        "\n",
        "        templates.append(t_block)\n",
        "\n",
        "data = {\"sequences\": sequences}\n",
        "if templates:\n",
        "    data[\"templates\"] = templates\n",
        "pocket_conditioning = bool(args.contact_residues and args.contact_residues.strip())\n",
        "\n",
        "if pocket_conditioning:\n",
        "    contacts = []\n",
        "    residues_chains = args.contact_residues.split(\"|\")\n",
        "    for i, residues_chain in enumerate(residues_chains):\n",
        "        residues = residues_chain.split(\",\")\n",
        "        contacts.extend([\n",
        "            [protein_chain_ids[i], int(res)]\n",
        "            for res in residues\n",
        "            if res.strip() != \"\"\n",
        "        ])\n",
        "    constraints = [{\"pocket\": {\"binder\": \"A\", \"contacts\": contacts}}]\n",
        "    data[\"constraints\"] = constraints\n",
        "    \n",
        "data[\"sequences\"] = sorted(\n",
        "    data[\"sequences\"], key=lambda entry: list(entry.values())[0][\"id\"][0]\n",
        ")\n",
        "\n",
        "any_ligand_or_nucleic = args.ligand_smiles or args.ligand_ccd or args.nucleic_seq\n",
        "model_type = \"ligand_mpnn\" if any_ligand_or_nucleic else \"soluble_mpnn\"\n",
        "\n",
        "print(\"‚úÖ Models ready and base data configured.\")\n",
        "print(\"Mode:\", args.mode)\n",
        "print(\"Data dictionary (base):\\n\", data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ct3W494Pxf6r"
      },
      "outputs": [],
      "source": [
        "# @title üöÄ Execute Design and Optimization Loop\n",
        "# Replicate the core logic from _run_design_cycle and run_pipeline's execution part\n",
        "import contextlib\n",
        "import shutil\n",
        "import io\n",
        "\n",
        "# NOTE: Using viewer object from global scope for incremental updates\n",
        "all_run_metrics = []\n",
        "\n",
        "for design_id in range(args.num_designs):\n",
        "    if viewer:\n",
        "        viewer = py2Dmol.view((600,400), color=\"plddt\")\n",
        "        viewer.show()\n",
        "\n",
        "\n",
        "    run_id = str(design_id)\n",
        "    run_save_dir = os.path.join(args.save_dir, f\"run_{run_id}\")\n",
        "    os.makedirs(run_save_dir, exist_ok=True)\n",
        "\n",
        "    data_cp = copy.deepcopy(data)\n",
        "\n",
        "    print(\"\\n=======================================================\")\n",
        "    print(f\"=== Starting Design Run {int(run_id)+1}/{int(args.num_designs)} ===\")\n",
        "    print(\"=======================================================\")\n",
        "\n",
        "    best_iptm = float(\"-inf\")\n",
        "    best_seq = None\n",
        "    best_structure = None\n",
        "    best_output = None\n",
        "    best_pdb_filename = None\n",
        "    best_cycle_idx = -1\n",
        "    best_alanine_percentage = None\n",
        "    run_metrics = {\"run_id\": run_id}\n",
        "\n",
        "    # --- Initial Sequence Assignment ---\n",
        "    binder_length = random.randint(\n",
        "        args.min_protein_length, args.max_protein_length\n",
        "    )\n",
        "    new_seq = sample_seq(binder_length, exclude_P=args.exclude_P, frac_X=args.percent_X/100)\n",
        "\n",
        "    # Update binder sequence in the data dictionary copy\n",
        "    for seq_entry in data_cp[\"sequences\"]:\n",
        "        if \"protein\" in seq_entry and args.binder_chain in seq_entry[\"protein\"][\"id\"]:\n",
        "            seq_entry[\"protein\"][\"sequence\"] = new_seq\n",
        "            break\n",
        "    print(f\"Binder initial sequence length: {binder_length}\")\n",
        "\n",
        "    # ========== Cycle 0 structure prediction (with contact filtering) ==========\n",
        "    contact_filter_attempt = 0\n",
        "    pdb_filename = \"\"\n",
        "    structure = None\n",
        "    output = None\n",
        "\n",
        "    while True:\n",
        "        # SUPPRESS UNWANTED MSA MESSAGES during prediction\n",
        "        with contextlib.redirect_stdout(io.StringIO()) as f:\n",
        "            output, structure = run_prediction(\n",
        "                data_cp,\n",
        "                args.binder_chain,\n",
        "                randomly_kill_helix_feature=args.randomly_kill_helix_feature,\n",
        "                negative_helix_constant=args.negative_helix_constant,\n",
        "                boltz_model=boltz_model,\n",
        "                ccd_lib=ccd_lib,\n",
        "                ccd_path=args.ccd_path,\n",
        "                logmd=args.logmd,\n",
        "                device=device,\n",
        "                boltz_model_version=args.boltz_model_version,\n",
        "                pocket_conditioning=pocket_conditioning,\n",
        "            )\n",
        "\n",
        "        # Save Cycle 0 PDB\n",
        "        pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_0.pdb\"\n",
        "        plddts = output[\"plddt\"].detach().cpu().numpy()[0]\n",
        "        save_pdb(structure, output[\"coords\"], plddts, pdb_filename)\n",
        "\n",
        "        # Contact filtering (only if configured)\n",
        "        contact_check_okay = True\n",
        "        if args.contact_residues.strip():\n",
        "            try:\n",
        "                binds = all(\n",
        "                    binder_binds_contacts(\n",
        "                        pdb_filename,\n",
        "                        args.binder_chain,\n",
        "                        protein_chain_ids[i],\n",
        "                        contact_res,\n",
        "                        cutoff=args.contact_cutoff,\n",
        "                    )\n",
        "                    for i, contact_res in enumerate(args.contact_residues.split(\"|\"))\n",
        "                )\n",
        "                if not binds:\n",
        "                    print(\n",
        "                        \"‚ùå Binder does NOT contact required residues after cycle 0. Retrying...\"\n",
        "                    )\n",
        "                    contact_check_okay = False\n",
        "            except Exception as e:\n",
        "                print(f\"WARNING: Could not perform binder-contact check: {e}\")\n",
        "                contact_check_okay = True\n",
        "\n",
        "        if contact_check_okay:\n",
        "            break\n",
        "        else:\n",
        "            contact_filter_attempt += 1\n",
        "            if contact_filter_attempt >= args.max_contact_filter_retries:\n",
        "                print(\"‚ö†Ô∏è Maximum contact filter retries reached. Proceeding anyway.\")\n",
        "                break\n",
        "\n",
        "            # Resample initial sequence\n",
        "            new_seq = sample_seq(\n",
        "                binder_length, exclude_P=args.exclude_P, frac_X=args.percent_X/100\n",
        "            )\n",
        "            for seq_entry in data_cp[\"sequences\"]:\n",
        "                if (\n",
        "                    \"protein\" in seq_entry\n",
        "                    and args.binder_chain in seq_entry[\"protein\"][\"id\"]\n",
        "                ):\n",
        "                    seq_entry[\"protein\"][\"sequence\"] = new_seq\n",
        "                    break\n",
        "            clean_memory()\n",
        "\n",
        "    # --- Capture Cycle 0 metrics (same logic as before) ---\n",
        "    binder_chain_idx = CHAIN_TO_NUMBER[args.binder_chain]\n",
        "    pair_chains = output[\"pair_chains_iptm\"]\n",
        "    if len(pair_chains) > 1:\n",
        "        values = [\n",
        "            (\n",
        "                pair_chains[binder_chain_idx][i].detach().cpu().numpy()\n",
        "                + pair_chains[i][binder_chain_idx].detach().cpu().numpy()\n",
        "            )\n",
        "            / 2.0\n",
        "            for i in range(len(pair_chains))\n",
        "            if i != binder_chain_idx\n",
        "        ]\n",
        "        cycle_0_iptm = float(np.mean(values) if values else 0.0)\n",
        "    else:\n",
        "        cycle_0_iptm = 0.0\n",
        "    run_metrics[\"cycle_0_iptm\"] = cycle_0_iptm\n",
        "    run_metrics[\"cycle_0_plddt\"] = float(\n",
        "        output.get(\"complex_plddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
        "    )\n",
        "    run_metrics[\"cycle_0_iplddt\"] = float(\n",
        "        output.get(\"complex_iplddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
        "    )\n",
        "    run_metrics[\"cycle_0_alanine\"] = 0\n",
        "    run_metrics[\"cycle_0_seq\"] = new_seq\n",
        "\n",
        "    # ===== Optimization Cycles (Cycle 1 to num_cycles) =====\n",
        "    for cycle in range(args.num_cycles):\n",
        "        print(f\"\\n--- Run {run_id}, Cycle {cycle + 1} ---\")\n",
        "\n",
        "        # Calculate temperature and bias\n",
        "        cycle_norm = (cycle / (args.num_cycles - 1)) if args.num_cycles > 1 else 0.0\n",
        "        alpha = args.alanine_bias_start - cycle_norm * (\n",
        "            args.alanine_bias_start - args.alanine_bias_end\n",
        "        )\n",
        "        temperature = args.temperature\n",
        "\n",
        "        design_kwargs = {\n",
        "            \"pdb_file\": pdb_filename,\n",
        "            \"temperature\": temperature,\n",
        "            \"chains_to_design\": args.binder_chain,\n",
        "            \"omit_AA\": f\"{args.omit_AA},P\" if cycle == 0 else args.omit_AA,\n",
        "        }\n",
        "        if args.alanine_bias:\n",
        "            design_kwargs[\"bias_AA\"] = f\"A:{alpha}\"\n",
        "\n",
        "        seq_str, logits = design_sequence(designer, model_type, **design_kwargs)\n",
        "        seq = seq_str.split(\":\")[CHAIN_TO_NUMBER[args.binder_chain]]\n",
        "\n",
        "        alanine_count = seq.count(\"A\")\n",
        "        alanine_percentage = alanine_count / binder_length if binder_length else 0.0\n",
        "        for seq_entry in data_cp[\"sequences\"]:\n",
        "            if (\n",
        "                \"protein\" in seq_entry\n",
        "                and args.binder_chain in seq_entry[\"protein\"][\"id\"]\n",
        "            ):\n",
        "                seq_entry[\"protein\"][\"sequence\"] = seq\n",
        "                break\n",
        "\n",
        "        # SUPPRESS UNWANTED MSA MESSAGES during prediction\n",
        "        with contextlib.redirect_stdout(io.StringIO()) as f:\n",
        "            output, structure = run_prediction(\n",
        "                data_cp,\n",
        "                args.binder_chain,\n",
        "                seq=seq,\n",
        "                randomly_kill_helix_feature=False,\n",
        "                negative_helix_constant=0.0,\n",
        "                boltz_model=boltz_model,\n",
        "                ccd_lib=ccd_lib,\n",
        "                ccd_path=args.ccd_path,\n",
        "                logmd=False,\n",
        "                device=device,\n",
        "            )\n",
        "\n",
        "        # Compute ipTM\n",
        "        current_chain_idx = CHAIN_TO_NUMBER[args.binder_chain]\n",
        "        pair_chains = output[\"pair_chains_iptm\"]\n",
        "        if len(pair_chains) > 1:\n",
        "            values = [\n",
        "                (\n",
        "                    pair_chains[current_chain_idx][i].detach().cpu().numpy()\n",
        "                    + pair_chains[i][current_chain_idx].detach().cpu().numpy()\n",
        "                )\n",
        "                / 2.0\n",
        "                for i in range(len(pair_chains))\n",
        "                if i != current_chain_idx\n",
        "            ]\n",
        "            current_iptm = float(np.mean(values) if values else 0.0)\n",
        "        else:\n",
        "            current_iptm = 0.0\n",
        "\n",
        "        # Update best structure\n",
        "        if alanine_percentage <= 0.20 and current_iptm > best_iptm:\n",
        "            best_iptm = current_iptm\n",
        "            best_structure = copy.deepcopy(structure)\n",
        "            best_output = shallow_copy_tensor_dict(output)\n",
        "            best_pdb_filename = (\n",
        "                f\"{run_save_dir}/{args.name}_run_{run_id}_best_structure.pdb\"\n",
        "            )\n",
        "            best_plddts = best_output[\"plddt\"].detach().cpu().numpy()[0]\n",
        "            save_pdb(\n",
        "                best_structure, best_output[\"coords\"], best_plddts, best_pdb_filename\n",
        "            )\n",
        "            best_cycle_idx = cycle + 1\n",
        "            best_seq = seq\n",
        "            best_alanine_percentage = alanine_percentage\n",
        "\n",
        "        # Record metrics\n",
        "        curr_plddt = float(\n",
        "            output.get(\"complex_plddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
        "        )\n",
        "        curr_iplddt = float(\n",
        "            output.get(\"complex_iplddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
        "        )\n",
        "        run_metrics[f\"cycle_{cycle + 1}_iptm\"] = current_iptm\n",
        "        run_metrics[f\"cycle_{cycle + 1}_plddt\"] = curr_plddt\n",
        "        run_metrics[f\"cycle_{cycle + 1}_iplddt\"] = curr_iplddt\n",
        "        run_metrics[f\"cycle_{cycle + 1}_alanine\"] = alanine_count\n",
        "        run_metrics[f\"cycle_{cycle + 1}_seq\"] = seq\n",
        "\n",
        "        print(\n",
        "            f\"ipTM: {current_iptm:.2f}, pLDDT: {curr_plddt:.2f}, iPLDDT: {curr_iplddt:.2f}, Ala%: {alanine_percentage * 100:.1f}\"\n",
        "        )\n",
        "\n",
        "        pdb_filename = (\n",
        "            f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_{cycle + 1}.pdb\"\n",
        "        )\n",
        "        plddts = output[\"plddt\"].detach().cpu().numpy()[0]\n",
        "        save_pdb(structure, output[\"coords\"], plddts, pdb_filename)\n",
        "\n",
        "        if viewer:\n",
        "            viewer.add_pdb(pdb_filename)\n",
        "\n",
        "        # 4. Save YAML for High ipTM\n",
        "        save_yaml_this_design = (alanine_percentage <= 0.20) and (\n",
        "            current_iptm > high_iptm_threshold and curr_plddt > high_plddt_threshold\n",
        "        )\n",
        "\n",
        "        if save_yaml_this_design and args.contact_residues.strip():\n",
        "            # Re-check contact binding before saving final YAML if constraints were used\n",
        "            this_cycle_pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_{cycle + 1}.pdb\"\n",
        "            try:\n",
        "                contact_binds = all(\n",
        "                    binder_binds_contacts(\n",
        "                        pdb_filename,\n",
        "                        args.binder_chain,\n",
        "                        protein_chain_ids[i],\n",
        "                        contact_res,\n",
        "                        cutoff=args.contact_cutoff,\n",
        "                    )\n",
        "                    for i, contact_res in enumerate(args.contact_residues.split(\"|\"))\n",
        "                )\n",
        "                if not contact_binds:\n",
        "                    save_yaml_this_design = False\n",
        "                    print(\n",
        "                        \"‚õîÔ∏è Not saving YAML: binder failed contact check for high ipTM save.\"\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                print(\n",
        "                    f\"WARNING: Exception during contact check: {e}. Saving YAML anyway.\"\n",
        "                )\n",
        "\n",
        "        if save_yaml_this_design:\n",
        "            high_iptm_yaml_dir = os.path.join(args.save_dir, \"high_iptm_yaml\")\n",
        "            os.makedirs(high_iptm_yaml_dir, exist_ok=True)\n",
        "            yaml_filename = os.path.join(\n",
        "                high_iptm_yaml_dir,\n",
        "                f\"{args.name}_run_{run_id}_cycle_{cycle + 1}_output.yaml\",\n",
        "            )\n",
        "            with open(yaml_filename, \"w\") as f:\n",
        "                yaml.dump(data_cp, f, default_flow_style=False)\n",
        "            high_iptm_pdb_dir = os.path.join(args.save_dir, \"high_iptm_pdb\")\n",
        "            os.makedirs(high_iptm_pdb_dir, exist_ok=True)\n",
        "            dest_pdb_path = os.path.join(high_iptm_pdb_dir, f\"{args.name}_run_{run_id}_cycle_{cycle + 1}_structure.pdb\")\n",
        "            shutil.copy(pdb_filename, dest_pdb_path)\n",
        "            print(f\"‚úÖ Saved run {run_id} cycle {cycle + 1} YAML.\")\n",
        "\n",
        "\n",
        "        clean_memory()\n",
        "\n",
        "    # --- Finalize and Plot Metrics ---\n",
        "    run_metrics[\"best_iptm\"] = float(\n",
        "        best_iptm if best_iptm != float(\"-inf\") else np.nan\n",
        "    )\n",
        "    run_metrics[\"best_cycle\"] = best_cycle_idx\n",
        "    run_metrics[\"best_seq\"] = best_seq\n",
        "    if best_output:\n",
        "        run_metrics[\"best_plddt\"] = float(\n",
        "            best_output.get(\"complex_plddt\", torch.tensor([np.nan]))\n",
        "            .detach()\n",
        "            .cpu()\n",
        "            .numpy()[0]\n",
        "        )\n",
        "    else:\n",
        "        run_metrics[\"best_plddt\"] = np.nan\n",
        "    all_run_metrics.append(run_metrics)\n",
        "\n",
        "    if args.plot:\n",
        "        plot_run_metrics(run_save_dir, args.name, run_id, args.num_cycles, run_metrics)\n",
        "\n",
        "\n",
        "# ===== Save All Run Metrics to CSV =====\n",
        "summary_csv = os.path.join(args.save_dir, \"summary_all_runs.csv\")\n",
        "df = pd.DataFrame(all_run_metrics)\n",
        "columns = [\"run_id\"]\n",
        "for i in range(args.num_cycles + 1):\n",
        "    columns.extend(\n",
        "        [\n",
        "            f\"cycle_{i}_iptm\",\n",
        "            f\"cycle_{i}_plddt\",\n",
        "            f\"cycle_{i}_iplddt\",\n",
        "            f\"cycle_{i}_alanine\",\n",
        "            f\"cycle_{i}_seq\",\n",
        "        ]\n",
        "    )\n",
        "columns.extend([\"best_iptm\", \"best_cycle\", \"best_plddt\", \"best_seq\"])\n",
        "\n",
        "for col in columns:\n",
        "    if col not in df.columns:\n",
        "        df[col] = np.nan\n",
        "df = df[[c for c in columns if c in df.columns]]\n",
        "df.to_csv(summary_csv, index=False)\n",
        "print(f\"\\n‚úÖ All run/cycle metrics saved to {summary_csv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v1miNZElTExp"
      },
      "outputs": [],
      "source": [
        "#@title download_prediction\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown Once this cell has been executed, a zip-archive with\n",
        "#@markdown the obtained prediction will be automatically downloaded\n",
        "#@markdown to your computer.\n",
        "\n",
        "# --- Download the predictions ---\n",
        "os.system(\"zip -r results.zip results\")\n",
        "files.download(\"results.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
