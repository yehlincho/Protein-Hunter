{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Protein Hunter Boltz Edition ‚ö°‚ú®üòà"
      ],
      "metadata": {
        "id": "BejWxwaeKIIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more details, read BoltzDesign1 paper **(https://www.biorxiv.org/content/10.1101/2025.10.10.681530v2.full.pdf)**\n",
        "\n",
        "**‚ùó Display Recommendation:**\n",
        "The viewer and visualization tools are optimized for light mode.\n",
        "\n",
        "**‚ùó WARNING:** the following pipeline is in active development and has NOT been experimentally validated in lab. We are releasing the code to allow the community to contribute and build on.\n",
        "\n",
        "**üìß Contact**\n",
        "For feedback, questions or collaboration opportunities, please email yehlin@mit.edu\n",
        "\n",
        "**‚û°Ô∏è Reference**\n",
        "We implemented the visualization of designing trajectories using logMD and py2Dmol"
      ],
      "metadata": {
        "id": "0n0K7DoLHSPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üõ†Ô∏è Fixed setup (~3 minutes)\n",
        "%%time\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# First, navigate to the correct directory\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# Install ProDy from GitHub\n",
        "os.system(\"pip install -q git+https://github.com/prody/ProDy.git\")\n",
        "\n",
        "if not os.path.isdir(\"Protein-Hunter\"):\n",
        "    print(\"Cloning Protein Hunter repository...\")\n",
        "    os.system(\"git clone https://github.com/yehlincho/Protein-Hunter.git\")\n",
        "    print(\"Installing LigandMPNN...\")\n",
        "    os.chdir(\"/content/Protein-Hunter/LigandMPNN\")\n",
        "    os.system(\"mkdir -p model_params\")\n",
        "    os.system(\"bash get_model_params.sh model_params\")\n",
        "    os.system(\"pip install -q ml_collections\")\n",
        "\n",
        "    print(\"Installing Boltz...\")\n",
        "    os.chdir(\"/content/Protein-Hunter/boltz_ph\")\n",
        "\n",
        "    # Install boltz with dependencies\n",
        "    os.system(\"pip install --no-dependencies .\")\n",
        "    os.system(\"pip install -q pypdb py3Dmol py2Dmol logmd tqdm\")\n",
        "    os.system(\"pip install pytorch_lightning \\\n",
        "    'rdkit~=2024.9.5' mashumaro \\\n",
        "    chembl_structure_pipeline \\\n",
        "    'gemmi~=0.6.5' ihm 'modelcif>=1.0' \\\n",
        "    fairscale einx\")\n",
        "\n",
        "    # Add boltz to Python path\n",
        "    boltz_path = \"/content/Protein-Hunter/boltz_ph\"\n",
        "    if boltz_path not in sys.path:\n",
        "        sys.path.insert(0, boltz_path)\n",
        "\n",
        "    os.chdir(\"/content\")\n",
        "else:\n",
        "    # If already installed, just add to path\n",
        "    boltz_path = \"/content/Protein-Hunter/boltz_ph\"\n",
        "    if boltz_path not in sys.path:\n",
        "        sys.path.insert(0, boltz_path)\n",
        "\n",
        "print(\"Setup complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuYz-SbMHPWF",
        "outputId": "85c2811b-939c-49fa-8e8b-0d092135297f",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete!\n",
            "CPU times: user 1.79 ms, sys: 119 ¬µs, total: 1.9 ms\n",
            "Wall time: 25.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üõ†Ô∏è download model weights\n",
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, \"/content/Protein-Hunter/boltz_ph/src\")\n",
        "from boltz.main import download_boltz2\n",
        "from pathlib import Path\n",
        "download_boltz2(Path(\".\"))\n",
        "print(\"Import successful!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR0MTxn1wBSA",
        "outputId": "ba8cd16d-2db1-428e-c032-81d4f4e3c0da",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[18:17:09] Initializing Normalizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß© Setup and Core Imports\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "import contextlib\n",
        "import io\n",
        "import copy\n",
        "import yaml\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Suppress warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.*\",\n",
        "    category=UserWarning,\n",
        ")\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/Protein-Hunter\")\n",
        "import py2Dmol\n",
        "from LigandMPNN.wrapper import LigandMPNNWrapper\n",
        "\n",
        "from boltz_ph.constants import CHAIN_TO_NUMBER\n",
        "from utils.metrics import get_CA_and_sequence # Used implicitly in design.py\n",
        "from utils.convert import calculate_holo_apo_rmsd, convert_cif_files_to_pdb\n",
        "# -----------------------------\n",
        "\n",
        "from boltz_ph.model_utils import (\n",
        "    binder_binds_contacts,\n",
        "    extract_sequence_from_structure,\n",
        "    clean_memory,\n",
        "    design_sequence,\n",
        "    get_boltz_model,\n",
        "    get_cif,\n",
        "    load_canonicals,\n",
        "    plot_from_pdb,\n",
        "    plot_run_metrics,\n",
        "    process_msa,\n",
        "    run_prediction,\n",
        "    sample_seq,\n",
        "    save_pdb,\n",
        "    shallow_copy_tensor_dict,\n",
        "    smart_split,\n",
        ")\n",
        "print(\"‚úÖ Core functionality imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "PJGAeh4OOXHz",
        "outputId": "2b459f10-7ff9-4332-f9f4-bac5fe1ae23b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Core functionality imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß¨ Boltz Configuration Parameters\n",
        "# --- General Setup ---\n",
        "gpu_id = 0  # @param {type:\"integer\"}\n",
        "grad_enabled = False  # @param {type:\"boolean\"}\n",
        "name = \"PDL1_SAM_binder\"  # @param {type:\"string\"}\n",
        "mode = \"binder\"  # @param [\"unconditional\", \"binder\"]\n",
        "num_designs = 2  # @param {type:\"integer\"}\n",
        "num_cycles = 5  # @param {type:\"integer\"}\n",
        "binder_chain = \"A\"  # @param {type:\"string\"}\n",
        "save_dir = f\"/content/results/{name}\"\n",
        "work_dir = os.getcwd()\n",
        "\n",
        "# --- Sequence Length ---\n",
        "min_design_protein_length = 100  # @param {type:\"integer\"}\n",
        "max_design_protein_length = 150  # @param {type:\"integer\"}\n",
        "\n",
        "# --- Target Protein(s) ---\n",
        "protein_ids = \"B\"  # @param {type:\"string\"}\n",
        "protein_seqs = \"MAQVQLVETGGGLVQPGGSLRLSCTASGFTFSMHAMTWYRQAPGKQRELVAVITSHGDRANYTDSVRGRFTISRDNTKNMVYLQMNSLKPEDTAVYYCNVPRYDSWGQGTQVTVSSGGLPET\"  # @param {type:\"string\"}\n",
        "protein_msas = \"\" # @param {type:\"string\"} means generate, \"empty\" is single sequence\n",
        "\n",
        "cyclics = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# --- Non-Protein Components (Ligand/Nucleic Acid) ---\n",
        "ligand_id = \"C\"\n",
        "ligand_smiles = \"\"  # @param {type:\"string\"}\n",
        "ligand_ccd = \"SAM\"  # @param {type:\"string\"}\n",
        "nucleic_type = \"dna\"\n",
        "nucleic_id = \"\"\n",
        "nucleic_seq = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# --- Templates and Constraints ---\n",
        "template_path = \"\"\n",
        "template_chain_id = \"\" # for prediction, which chain to provide the template\n",
        "template_cif_chain_id = \"\" # for mmCIF files, which chain from mmcif file to use for the template\n",
        "add_constraints = False  # @param {type:\"boolean\"}\n",
        "contact_residues = \"\"  # e.g., \"1,2,5,10\" on target chain # @param {type:\"string\"}\n",
        "constraint_target_chain = \"B\"  # Target chain for contacts # @param {type:\"string\"}\n",
        "contact_cutoff = 10.0  # @param {type:\"number\"}\n",
        "max_contact_filter_retries = 6  # @param {type:\"integer\"}\n",
        "no_contact_filter = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# --- Model & Diffusion Parameters ---\n",
        "no_potentials = True  # @param {type:\"boolean\"}\n",
        "diffuse_steps = 200  # @param {type:\"integer\"}\n",
        "recycling_steps = 3  # @param {type:\"integer\"}\n",
        "boltz_model_version = \"boltz2\"  # @param [\"boltz1\", \"boltz2\"]\n",
        "boltz_model_path = \"/content/boltz2_conf.ckpt\"\n",
        "ccd_path = \"/content/mols\"\n",
        "\n",
        "logmd = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# --- Design & Optimization ---\n",
        "randomly_kill_helix_feature = False  # @param {type:\"boolean\"}\n",
        "negative_helix_constant = 0.2  # @param {type:\"number\"}\n",
        "alanine_bias = True  # @param {type:\"boolean\"}\n",
        "temperature_start = 0.05  # @param {type:\"number\"}\n",
        "temperature_end = 0.001  # @param {type:\"number\"}\n",
        "alanine_bias_start = -0.5  # @param {type:\"number\"}\n",
        "alanine_bias_end = -0.2  # @param {type:\"number\"}\n",
        "omit_AA = \"C\"  # @param {type:\"string\"}\n",
        "exclude_P = False  # @param {type:\"boolean\"}\n",
        "frac_X = 0.5  # @param {type:\"number\"}\n",
        "high_iptm_threshold = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "plot = True  # @param {type:\"boolean\"}\n",
        "viewer = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# Re-package parameters into an 'args' object (simple class for dot notation)\n",
        "class Args:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "\n",
        "args = Args(**locals())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mXmBIVkVOpYa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚öôÔ∏è Initialize Models and Prepare Base Data\n",
        "# --- 1. Model Initialization ---\n",
        "device = (\n",
        "    f\"cuda:{args.gpu_id}\" if torch.cuda.is_available() and args.gpu_id >= 0 else \"cpu\"\n",
        ")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "predict_args = {\n",
        "    \"recycling_steps\": args.recycling_steps,\n",
        "    \"sampling_steps\": args.diffuse_steps,\n",
        "    \"diffusion_samples\": 1,\n",
        "    \"write_confidence_summary\": True,\n",
        "    \"write_full_pae\": False,\n",
        "    \"write_full_pde\": False,\n",
        "    \"max_parallel_samples\": 1,\n",
        "}\n",
        "\n",
        "ccd_lib = load_canonicals(os.path.expanduser(str(args.ccd_path)))\n",
        "boltz_model = get_boltz_model(\n",
        "    checkpoint=args.boltz_model_path,\n",
        "    predict_args=predict_args,\n",
        "    device=device,\n",
        "    model_version=args.boltz_model_version,\n",
        "    no_potentials=args.no_potentials,\n",
        "    grad_enabled=args.grad_enabled,\n",
        ")\n",
        "designer = LigandMPNNWrapper(os.path.join(args.work_dir, \"/content/Protein-Hunter/LigandMPNN/run.py\"))\n",
        "protein_hunter_save_dir = os.path.join(args.save_dir, \"0_protein_hunter_design\")\n",
        "os.makedirs(protein_hunter_save_dir, exist_ok=True)\n",
        "os.makedirs(args.save_dir, exist_ok=True)\n",
        "\n",
        "# --- 2. Data Preparation (Condensed from _build_initial_data_dict) ---\n",
        "sequences = []\n",
        "# Process multi-chain/MSA inputs\n",
        "protein_ids_list = smart_split(args.protein_ids)\n",
        "protein_seqs_list = smart_split(args.protein_seqs)\n",
        "protein_msas_list = (\n",
        "    smart_split(args.protein_msas)\n",
        "    if args.protein_msas\n",
        "    else [\"\"] * len(protein_ids_list)\n",
        ")\n",
        "cyclics_list = (\n",
        "    smart_split(args.cyclics) if args.cyclics else [\"False\"] * len(protein_ids_list)\n",
        ")\n",
        "\n",
        "max_len = max(\n",
        "    len(protein_ids_list),\n",
        "    len(protein_seqs_list),\n",
        "    len(protein_msas_list),\n",
        "    len(cyclics_list),\n",
        ")\n",
        "for l in [protein_ids_list, protein_seqs_list, protein_msas_list, cyclics_list]:\n",
        "    while len(l) < max_len:\n",
        "        l.append(\"\")\n",
        "\n",
        "seq_to_indices = defaultdict(list)\n",
        "for idx, seq in enumerate(protein_seqs_list):\n",
        "    if seq:\n",
        "        seq_to_indices[seq].append(idx)\n",
        "seq_to_final_msa = {}\n",
        "\n",
        "# Suppress MSA generation output during this phase\n",
        "with contextlib.redirect_stdout(io.StringIO()) as f:\n",
        "    for seq, idx_list in seq_to_indices.items():\n",
        "        chosen_msa = next(\n",
        "            (\n",
        "                protein_msas_list[i]\n",
        "                for i in idx_list\n",
        "                if protein_msas_list[i] and protein_msas_list[i] != \"empty\"\n",
        "            ),\n",
        "            None,\n",
        "        )\n",
        "        if chosen_msa is None:\n",
        "            chosen_msa = \"\"\n",
        "\n",
        "        if chosen_msa == \"\":\n",
        "            pid = (\n",
        "                protein_ids_list[idx_list[0]]\n",
        "                if protein_ids_list[idx_list[0]]\n",
        "                else f\"CHAIN_{idx_list[0]}\"\n",
        "            )\n",
        "            msa_value = process_msa(pid, seq, Path(protein_hunter_save_dir))\n",
        "            seq_to_final_msa[seq] = str(msa_value)\n",
        "        elif chosen_msa == \"empty\":\n",
        "            seq_to_final_msa[seq] = \"empty\"\n",
        "        else:\n",
        "            seq_to_final_msa[seq] = chosen_msa\n",
        "\n",
        "# Build sequences list and add X-binder\n",
        "for pid, seq, cyc in zip(protein_ids_list, protein_seqs_list, cyclics_list):\n",
        "    if not pid or not seq:\n",
        "        continue\n",
        "    final_msa = seq_to_final_msa.get(seq, \"empty\")\n",
        "    cyc_val = cyc.lower() in [\"true\", \"1\", \"yes\"]\n",
        "    sequences.append(\n",
        "        {\"protein\": {\"id\": [pid], \"sequence\": seq, \"msa\": final_msa, \"cyclic\": cyc_val}}\n",
        "    )\n",
        "sequences.append(\n",
        "    {\n",
        "        \"protein\": {\n",
        "            \"id\": [args.binder_chain],\n",
        "            \"sequence\": \"X\",\n",
        "            \"msa\": \"empty\",\n",
        "            \"cyclic\": False,\n",
        "        }\n",
        "    }\n",
        ")\n",
        "if args.ligand_smiles:\n",
        "    sequences.append({\"ligand\": {\"id\": [args.ligand_id], \"smiles\": args.ligand_smiles}})\n",
        "elif args.ligand_ccd:\n",
        "    sequences.append({\"ligand\": {\"id\": [args.ligand_id], \"ccd\": args.ligand_ccd}})\n",
        "if args.nucleic_seq:\n",
        "    sequences.append(\n",
        "        {args.nucleic_type: {\"id\": [args.nucleic_id], \"sequence\": args.nucleic_seq}}\n",
        "    )\n",
        "# Handle templates and constraints\n",
        "templates = []\n",
        "if args.template_path:\n",
        "    template_path_list = smart_split(args.template_path)\n",
        "    template_chain_id_list = (\n",
        "        smart_split(args.template_chain_id) if args.template_chain_id else []\n",
        "    )\n",
        "    template_cif_chain_id_list = (\n",
        "        smart_split(args.template_cif_chain_id) if args.template_cif_chain_id else []\n",
        "    )\n",
        "    template_files = [get_cif(tp) for tp in template_path_list]\n",
        "    for i, template_file in enumerate(template_files):\n",
        "        t_block = (\n",
        "            {\"cif\": template_file}\n",
        "            if template_file.endswith(\".cif\")\n",
        "            else {\"pdb\": template_file}\n",
        "        )\n",
        "        if template_chain_id_list and i < len(template_chain_id_list):\n",
        "            t_block[\"chain_id\"] = template_chain_id_list[i]\n",
        "            t_block[\"cif_chain_id\"] = template_cif_chain_id_list[i]\n",
        "\n",
        "        templates.append(t_block)\n",
        "\n",
        "data = {\"sequences\": sequences}\n",
        "if templates:\n",
        "    data[\"templates\"] = templates\n",
        "pocket_conditioning = args.add_constraints\n",
        "\n",
        "if args.add_constraints:\n",
        "    residues = args.contact_residues.split(\",\")\n",
        "    contacts = [\n",
        "        [args.constraint_target_chain, int(res)]\n",
        "        for res in residues\n",
        "        if res.strip() != \"\"\n",
        "    ]\n",
        "    constraints = [{\"pocket\": {\"binder\": args.binder_chain, \"contacts\": contacts}}]\n",
        "    data[\"constraints\"] = constraints\n",
        "\n",
        "data[\"sequences\"] = sorted(\n",
        "    data[\"sequences\"], key=lambda entry: list(entry.values())[0][\"id\"][0]\n",
        ")\n",
        "\n",
        "any_ligand_or_nucleic = args.ligand_smiles or args.ligand_ccd or args.nucleic_seq\n",
        "model_type = \"ligand_mpnn\" if any_ligand_or_nucleic else \"soluble_mpnn\"\n",
        "\n",
        "print(\"‚úÖ Models ready and base data configured.\")\n",
        "print(\"Mode:\", args.mode)\n",
        "print(\"Data dictionary (base):\\n\", data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Fo1Dix4sPTGG",
        "outputId": "d469c5b4-c484-4b2e-f79f-ab1cc61a772a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMPLETE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [elapsed: 00:02 remaining: 00:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Models ready and base data configured.\n",
            "Mode: binder\n",
            "Data dictionary (base):\n",
            " {'sequences': [{'protein': {'id': ['A'], 'sequence': 'X', 'msa': 'empty', 'cyclic': False}}, {'protein': {'id': ['B'], 'sequence': 'MAQVQLVETGGGLVQPGGSLRLSCTASGFTFSMHAMTWYRQAPGKQRELVAVITSHGDRANYTDSVRGRFTISRDNTKNMVYLQMNSLKPEDTAVYYCNVPRYDSWGQGTQVTVSSGGLPET', 'msa': '/content/results/PDL1_SAM_binder/0_protein_hunter_design/B_env/msa.npz', 'cyclic': False}}, {'ligand': {'id': ['C'], 'ccd': 'SAM'}}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Execute Design and Optimization Loop\n",
        "# Replicate the core logic from _run_design_cycle and run_pipeline's execution part\n",
        "import contextlib\n",
        "import io\n",
        "\n",
        "# NOTE: Using viewer object from global scope for incremental updates\n",
        "all_run_metrics = []\n",
        "\n",
        "for design_id in range(args.num_designs):\n",
        "    if viewer:\n",
        "        viewer = py2Dmol.view((600,400), color=\"plddt\")\n",
        "        viewer.show()\n",
        "\n",
        "\n",
        "    run_id = str(design_id)\n",
        "    run_save_dir = os.path.join(args.save_dir, f\"run_{run_id}\")\n",
        "    os.makedirs(run_save_dir, exist_ok=True)\n",
        "\n",
        "    data_cp = copy.deepcopy(data)\n",
        "\n",
        "    print(\"\\n=======================================================\")\n",
        "    print(f\"=== Starting Design Run {run_id}/{args.num_designs - 1} ===\")\n",
        "    print(\"=======================================================\")\n",
        "\n",
        "    best_iptm = float(\"-inf\")\n",
        "    best_seq = None\n",
        "    best_structure = None\n",
        "    best_output = None\n",
        "    best_pdb_filename = None\n",
        "    best_cycle_idx = -1\n",
        "    best_alanine_percentage = None\n",
        "    run_metrics = {\"run_id\": run_id}\n",
        "\n",
        "    # --- Initial Sequence Assignment ---\n",
        "    binder_length = random.randint(\n",
        "        args.min_design_protein_length, args.max_design_protein_length\n",
        "    )\n",
        "    new_seq = sample_seq(binder_length, exclude_P=args.exclude_P, frac_X=args.frac_X)\n",
        "\n",
        "    # Update binder sequence in the data dictionary copy\n",
        "    for seq_entry in data_cp[\"sequences\"]:\n",
        "        if \"protein\" in seq_entry and args.binder_chain in seq_entry[\"protein\"][\"id\"]:\n",
        "            seq_entry[\"protein\"][\"sequence\"] = new_seq\n",
        "            break\n",
        "    print(f\"Binder initial sequence length: {binder_length}\")\n",
        "\n",
        "    # ========== Cycle 0 structure prediction (with contact filtering) ==========\n",
        "    contact_filter_attempt = 0\n",
        "    pdb_filename = \"\"\n",
        "    structure = None\n",
        "    output = None\n",
        "\n",
        "    while True:\n",
        "        # SUPPRESS UNWANTED MSA MESSAGES during prediction\n",
        "        with contextlib.redirect_stdout(io.StringIO()) as f:\n",
        "            output, structure = run_prediction(\n",
        "                data_cp,\n",
        "                args.binder_chain,\n",
        "                randomly_kill_helix_feature=args.randomly_kill_helix_feature,\n",
        "                negative_helix_constant=args.negative_helix_constant,\n",
        "                boltz_model=boltz_model,\n",
        "                ccd_lib=ccd_lib,\n",
        "                ccd_path=args.ccd_path,\n",
        "                logmd=args.logmd,\n",
        "                device=device,\n",
        "                boltz_model_version=args.boltz_model_version,\n",
        "                pocket_conditioning=pocket_conditioning,\n",
        "            )\n",
        "\n",
        "        # Save Cycle 0 PDB\n",
        "        pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_0.pdb\"\n",
        "        plddts = output[\"plddt\"].detach().cpu().numpy()[0]\n",
        "        save_pdb(structure, output[\"coords\"], plddts, pdb_filename)\n",
        "\n",
        "        # Contact filtering (only if configured)\n",
        "        contact_check_okay = True\n",
        "        if args.contact_residues.strip() and not args.no_contact_filter:\n",
        "            try:\n",
        "                binds = binder_binds_contacts(\n",
        "                    pdb_filename,\n",
        "                    args.binder_chain,\n",
        "                    args.constraint_target_chain,\n",
        "                    args.contact_residues,\n",
        "                    cutoff=args.contact_cutoff,\n",
        "                )\n",
        "                if not binds:\n",
        "                    print(\n",
        "                        \"‚ùå Binder does NOT contact required residues after cycle 0. Retrying...\"\n",
        "                    )\n",
        "                    contact_check_okay = False\n",
        "            except Exception as e:\n",
        "                print(f\"WARNING: Could not perform binder-contact check: {e}\")\n",
        "                contact_check_okay = True\n",
        "\n",
        "        if contact_check_okay:\n",
        "            break\n",
        "        else:\n",
        "            contact_filter_attempt += 1\n",
        "            if contact_filter_attempt >= args.max_contact_filter_retries:\n",
        "                print(\"‚ö†Ô∏è Maximum contact filter retries reached. Proceeding anyway.\")\n",
        "                break\n",
        "\n",
        "            # Resample initial sequence\n",
        "            new_seq = sample_seq(\n",
        "                binder_length, exclude_P=args.exclude_P, frac_X=args.frac_X\n",
        "            )\n",
        "            for seq_entry in data_cp[\"sequences\"]:\n",
        "                if (\n",
        "                    \"protein\" in seq_entry\n",
        "                    and args.binder_chain in seq_entry[\"protein\"][\"id\"]\n",
        "                ):\n",
        "                    seq_entry[\"protein\"][\"sequence\"] = new_seq\n",
        "                    break\n",
        "            clean_memory()\n",
        "\n",
        "    # --- Capture Cycle 0 metrics (same logic as before) ---\n",
        "    binder_chain_idx = CHAIN_TO_NUMBER[args.binder_chain]\n",
        "    pair_chains = output[\"pair_chains_iptm\"]\n",
        "    if len(pair_chains) > 1:\n",
        "        values = [\n",
        "            (\n",
        "                pair_chains[binder_chain_idx][i].detach().cpu().numpy()\n",
        "                + pair_chains[i][binder_chain_idx].detach().cpu().numpy()\n",
        "            )\n",
        "            / 2.0\n",
        "            for i in range(len(pair_chains))\n",
        "            if i != binder_chain_idx\n",
        "        ]\n",
        "        cycle_0_iptm = float(np.mean(values) if values else 0.0)\n",
        "    else:\n",
        "        cycle_0_iptm = 0.0\n",
        "    run_metrics[\"cycle_0_iptm\"] = cycle_0_iptm\n",
        "    run_metrics[\"cycle_0_plddt\"] = float(\n",
        "        output.get(\"complex_plddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
        "    )\n",
        "    run_metrics[\"cycle_0_iplddt\"] = float(\n",
        "        output.get(\"complex_iplddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
        "    )\n",
        "    run_metrics[\"cycle_0_alanine\"] = 0\n",
        "    run_metrics[\"cycle_0_seq\"] = new_seq\n",
        "\n",
        "    # ===== Optimization Cycles (Cycle 1 to num_cycles) =====\n",
        "    for cycle in range(args.num_cycles):\n",
        "        print(f\"\\n--- Run {run_id}, Cycle {cycle + 1} ---\")\n",
        "\n",
        "        # Calculate temperature and bias\n",
        "        cycle_norm = (cycle / (args.num_cycles - 1)) if args.num_cycles > 1 else 0.0\n",
        "        alpha = args.alanine_bias_start - cycle_norm * (\n",
        "            args.alanine_bias_start - args.alanine_bias_end\n",
        "        )\n",
        "        temperature = args.temperature_start - cycle_norm * (\n",
        "            args.temperature_start - args.temperature_end\n",
        "        )\n",
        "\n",
        "        design_kwargs = {\n",
        "            \"pdb_file\": pdb_filename,\n",
        "            \"temperature\": temperature,\n",
        "            \"chains_to_design\": args.binder_chain,\n",
        "            \"omit_AA\": f\"{args.omit_AA},P\" if cycle == 0 else args.omit_AA,\n",
        "        }\n",
        "        if args.alanine_bias:\n",
        "            design_kwargs[\"bias_AA\"] = f\"A:{alpha}\"\n",
        "\n",
        "        seq_str, logits = design_sequence(designer, model_type, **design_kwargs)\n",
        "        seq = seq_str.split(\":\")[CHAIN_TO_NUMBER[args.binder_chain]]\n",
        "\n",
        "        alanine_count = seq.count(\"A\")\n",
        "        alanine_percentage = alanine_count / binder_length if binder_length else 0.0\n",
        "        for seq_entry in data_cp[\"sequences\"]:\n",
        "            if (\n",
        "                \"protein\" in seq_entry\n",
        "                and args.binder_chain in seq_entry[\"protein\"][\"id\"]\n",
        "            ):\n",
        "                seq_entry[\"protein\"][\"sequence\"] = seq\n",
        "                break\n",
        "\n",
        "        # SUPPRESS UNWANTED MSA MESSAGES during prediction\n",
        "        with contextlib.redirect_stdout(io.StringIO()) as f:\n",
        "            output, structure = run_prediction(\n",
        "                data_cp,\n",
        "                args.binder_chain,\n",
        "                seq=seq,\n",
        "                randomly_kill_helix_feature=False,\n",
        "                negative_helix_constant=0.0,\n",
        "                boltz_model=boltz_model,\n",
        "                ccd_lib=ccd_lib,\n",
        "                ccd_path=args.ccd_path,\n",
        "                logmd=False,\n",
        "                device=device,\n",
        "            )\n",
        "\n",
        "        # Compute ipTM\n",
        "        current_chain_idx = CHAIN_TO_NUMBER[args.binder_chain]\n",
        "        pair_chains = output[\"pair_chains_iptm\"]\n",
        "        if len(pair_chains) > 1:\n",
        "            values = [\n",
        "                (\n",
        "                    pair_chains[current_chain_idx][i].detach().cpu().numpy()\n",
        "                    + pair_chains[i][current_chain_idx].detach().cpu().numpy()\n",
        "                )\n",
        "                / 2.0\n",
        "                for i in range(len(pair_chains))\n",
        "                if i != current_chain_idx\n",
        "            ]\n",
        "            current_iptm = float(np.mean(values) if values else 0.0)\n",
        "        else:\n",
        "            current_iptm = 0.0\n",
        "\n",
        "        # Update best structure\n",
        "        if alanine_percentage <= 0.20 and current_iptm > best_iptm:\n",
        "            best_iptm = current_iptm\n",
        "            best_structure = copy.deepcopy(structure)\n",
        "            best_output = shallow_copy_tensor_dict(output)\n",
        "            best_pdb_filename = (\n",
        "                f\"{run_save_dir}/{args.name}_run_{run_id}_best_structure.pdb\"\n",
        "            )\n",
        "            best_plddts = best_output[\"plddt\"].detach().cpu().numpy()[0]\n",
        "            save_pdb(\n",
        "                best_structure, best_output[\"coords\"], best_plddts, best_pdb_filename\n",
        "            )\n",
        "            best_cycle_idx = cycle + 1\n",
        "            best_seq = seq\n",
        "            best_alanine_percentage = alanine_percentage\n",
        "\n",
        "        # Record metrics\n",
        "        curr_plddt = float(\n",
        "            output.get(\"complex_plddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
        "        )\n",
        "        curr_iplddt = float(\n",
        "            output.get(\"complex_iplddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
        "        )\n",
        "        run_metrics[f\"cycle_{cycle + 1}_iptm\"] = current_iptm\n",
        "        run_metrics[f\"cycle_{cycle + 1}_plddt\"] = curr_plddt\n",
        "        run_metrics[f\"cycle_{cycle + 1}_iplddt\"] = curr_iplddt\n",
        "        run_metrics[f\"cycle_{cycle + 1}_alanine\"] = alanine_count\n",
        "        run_metrics[f\"cycle_{cycle + 1}_seq\"] = seq\n",
        "\n",
        "        print(\n",
        "            f\"ipTM: {current_iptm:.2f}, pLDDT: {curr_plddt:.2f}, iPLDDT: {curr_iplddt:.2f}, Ala%: {alanine_percentage * 100:.1f}\"\n",
        "        )\n",
        "\n",
        "        pdb_filename = (\n",
        "            f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_{cycle + 1}.pdb\"\n",
        "        )\n",
        "        plddts = output[\"plddt\"].detach().cpu().numpy()[0]\n",
        "        save_pdb(structure, output[\"coords\"], plddts, pdb_filename)\n",
        "\n",
        "        if viewer:\n",
        "            viewer.add_pdb(pdb_filename)\n",
        "\n",
        "        # 4. Save YAML for High ipTM\n",
        "        save_yaml_this_design = (alanine_percentage <= 0.20) and (\n",
        "            current_iptm > high_iptm_threshold\n",
        "        )\n",
        "\n",
        "        if save_yaml_this_design and args.contact_residues.strip():\n",
        "            # Re-check contact binding before saving final YAML if constraints were used\n",
        "            this_cycle_pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_{cycle + 1}.pdb\"\n",
        "            try:\n",
        "                contact_binds = binder_binds_contacts(\n",
        "                    this_cycle_pdb_filename,\n",
        "                    args.binder_chain,\n",
        "                    args.constraint_target_chain,\n",
        "                    args.contact_residues,\n",
        "                    cutoff=args.contact_cutoff,\n",
        "                )\n",
        "                if not contact_binds:\n",
        "                    save_yaml_this_design = False\n",
        "                    print(\n",
        "                        \"‚õîÔ∏è Not saving YAML: binder failed contact check for high ipTM save.\"\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                print(\n",
        "                    f\"WARNING: Exception during contact check: {e}. Saving YAML anyway.\"\n",
        "                )\n",
        "\n",
        "        if save_yaml_this_design:\n",
        "            high_iptm_yaml_dir = os.path.join(args.save_dir, \"high_iptm_yaml\")\n",
        "            os.makedirs(high_iptm_yaml_dir, exist_ok=True)\n",
        "            yaml_filename = os.path.join(\n",
        "                high_iptm_yaml_dir,\n",
        "                f\"{args.name}_run_{run_id}_cycle_{cycle + 1}_output.yaml\",\n",
        "            )\n",
        "            with open(yaml_filename, \"w\") as f:\n",
        "                yaml.dump(data_cp, f, default_flow_style=False)\n",
        "            print(f\"‚úÖ Saved run {run_id} cycle {cycle + 1} YAML.\")\n",
        "\n",
        "\n",
        "        clean_memory()\n",
        "\n",
        "    # --- Finalize and Plot Metrics ---\n",
        "    run_metrics[\"best_iptm\"] = float(\n",
        "        best_iptm if best_iptm != float(\"-inf\") else np.nan\n",
        "    )\n",
        "    run_metrics[\"best_cycle\"] = best_cycle_idx\n",
        "    run_metrics[\"best_seq\"] = best_seq\n",
        "    if best_output:\n",
        "        run_metrics[\"best_plddt\"] = float(\n",
        "            best_output.get(\"complex_plddt\", torch.tensor([np.nan]))\n",
        "            .detach()\n",
        "            .cpu()\n",
        "            .numpy()[0]\n",
        "        )\n",
        "    else:\n",
        "        run_metrics[\"best_plddt\"] = np.nan\n",
        "    all_run_metrics.append(run_metrics)\n",
        "\n",
        "    if args.plot:\n",
        "        plot_run_metrics(run_save_dir, args.name, run_id, args.num_cycles, run_metrics)\n",
        "\n",
        "\n",
        "# ===== Save All Run Metrics to CSV =====\n",
        "summary_csv = os.path.join(args.save_dir, \"summary_all_runs.csv\")\n",
        "df = pd.DataFrame(all_run_metrics)\n",
        "columns = [\"run_id\"]\n",
        "for i in range(args.num_cycles + 1):\n",
        "    columns.extend(\n",
        "        [\n",
        "            f\"cycle_{i}_iptm\",\n",
        "            f\"cycle_{i}_plddt\",\n",
        "            f\"cycle_{i}_iplddt\",\n",
        "            f\"cycle_{i}_alanine\",\n",
        "            f\"cycle_{i}_seq\",\n",
        "        ]\n",
        "    )\n",
        "columns.extend([\"best_iptm\", \"best_cycle\", \"best_plddt\", \"best_seq\"])\n",
        "\n",
        "for col in columns:\n",
        "    if col not in df.columns:\n",
        "        df[col] = np.nan\n",
        "df = df[[c for c in columns if c in df.columns]]\n",
        "df.to_csv(summary_csv, index=False)\n",
        "print(f\"\\n‚úÖ All run/cycle metrics saved to {summary_csv}\")"
      ],
      "metadata": {
        "id": "ct3W494Pxf6r",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download_prediction\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown Once this cell has been executed, a zip-archive with\n",
        "#@markdown the obtained prediction will be automatically downloaded\n",
        "#@markdown to your computer.\n",
        "\n",
        "# --- Download the predictions ---\n",
        "os.system(\"zip -r results.zip results\")\n",
        "files.download(\"results.zip\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "v1miNZElTExp"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}